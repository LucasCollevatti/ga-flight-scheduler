{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5118,
     "status": "ok",
     "timestamp": 1763659602031,
     "user": {
      "displayName": "Lucas Collevatti",
      "userId": "15100666009399473044"
     },
     "user_tz": 180
    },
    "id": "XBjnigcRKcIm",
    "outputId": "df9ed8d6-0da6-410a-a180-3666f67f036f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos vão ser salvos em: C:\\Users\\lucas\\Projects\\Softwares\\PSI3472\\airnet_inputs\n",
      "Config:\n",
      " - Dia: 360 -> 1320 (min)\n",
      " - Slot: 60 min\n",
      " - Frota: 250 aeronaves de 200 lugares\n"
     ]
    }
   ],
   "source": [
    "# A1 - Configuração base (uso LOCAL, sem Google Drive)\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pasta base ONDE vão ficar todos os CSV/JSON\n",
    "# Agora usando caminho RELATIVO ao projeto / notebook:\n",
    "# - Se existir uma pasta \"airnet_inputs\" na pasta atual, usa ela.\n",
    "# - Senão, procura \"airnet_inputs\" na pasta mãe (por ex. quando o notebook está em \"notebooks/\").\n",
    "NOTEBOOK_DIR = Path().resolve()\n",
    "if (NOTEBOOK_DIR / \"airnet_inputs\").exists():\n",
    "    BASE_DIR = (NOTEBOOK_DIR / \"airnet_inputs\").resolve()\n",
    "else:\n",
    "    BASE_DIR = (NOTEBOOK_DIR.parent / \"airnet_inputs\").resolve()\n",
    "\n",
    "BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Arquivos vão ser salvos em:\", BASE_DIR)\n",
    "\n",
    "# ===========================\n",
    "# CONFIGURAÇÃO GLOBAL\n",
    "# ===========================\n",
    "\n",
    "DAY_START = 6 * 60    # 06:00 em minutos\n",
    "DAY_END   = 22 * 60   # 22:00 em minutos\n",
    "SLOT_MIN  = 60        # todos os voos em horas inteiras\n",
    "\n",
    "TURNAROUND_MIN = 60   # mínimo entre pouso e nova decolagem (aeronave)\n",
    "MIN_CONN_MIN   = 60   # conexão mínima passageiro\n",
    "\n",
    "FLEET_N   = 250       # aeronaves\n",
    "SEATS_PER = 200       # assentos por aeronave\n",
    "\n",
    "print(\"Config:\")\n",
    "print(\" - Dia:\", DAY_START, \"->\", DAY_END, \"(min)\")\n",
    "print(\" - Slot:\", SLOT_MIN, \"min\")\n",
    "print(\" - Frota:\", FLEET_N, \"aeronaves de\", SEATS_PER, \"lugares\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1763659602032,
     "user": {
      "displayName": "Lucas Collevatti",
      "userId": "15100666009399473044"
     },
     "user_tz": 180
    },
    "id": "haMPiEBpKeSu",
    "outputId": "ede64324-2274-4018-aa47-ed452dd2f6e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvos:\n",
      " - C:\\Users\\lucas\\Projects\\Softwares\\PSI3472\\airnet_inputs\\airports.csv\n",
      " - C:\\Users\\lucas\\Projects\\Softwares\\PSI3472\\airnet_inputs\\airports.json\n"
     ]
    }
   ],
   "source": [
    "# A2 - Definir os 14 aeroportos (códigos do enunciado) e salvar\n",
    "\n",
    "# Ordem PADRÃO em todas as tabelas\n",
    "airport_codes = [\n",
    "    \"MA\", \"BE\", \"FO\", \"NA\", \"RE\", \"SA\", \"BR\",\n",
    "    \"BH\", \"CI\", \"RJ\", \"SP\", \"CR\", \"FL\", \"PA\"\n",
    "]\n",
    "\n",
    "airport_names = [\n",
    "    \"Manaus\",\n",
    "    \"Belém\",\n",
    "    \"Fortaleza\",\n",
    "    \"Natal\",\n",
    "    \"Recife\",\n",
    "    \"Salvador\",\n",
    "    \"Brasília\",\n",
    "    \"Belo Horizonte\",\n",
    "    \"Cuiabá\",\n",
    "    \"Rio de Janeiro\",\n",
    "    \"São Paulo\",\n",
    "    \"Curitiba\",\n",
    "    \"Florianópolis\",\n",
    "    \"Porto Alegre\",\n",
    "]\n",
    "\n",
    "# lat/lon aproximados só pra plot / mapa (não importam para o GA)\n",
    "airport_lat = [\n",
    "    -3.1190,   # MA - Manaus\n",
    "    -1.4558,   # BE - Belém\n",
    "    -3.7172,   # FO - Fortaleza\n",
    "    -5.7945,   # NA - Natal\n",
    "    -8.0476,   # RE - Recife\n",
    "    -12.9777,  # SA - Salvador\n",
    "    -15.7939,  # BR - Brasília\n",
    "    -19.9167,  # BH - Belo Horizonte\n",
    "    -15.6010,  # CI - Cuiabá\n",
    "    -22.9068,  # RJ - Rio de Janeiro\n",
    "    -23.5505,  # SP - São Paulo\n",
    "    -25.4284,  # CR - Curitiba\n",
    "    -27.5954,  # FL - Florianópolis\n",
    "    -30.0346,  # PA - Porto Alegre\n",
    "]\n",
    "\n",
    "airport_lon = [\n",
    "    -60.0217,  # MA\n",
    "    -48.4902,  # BE\n",
    "    -38.5434,  # FO\n",
    "    -35.2110,  # NA\n",
    "    -34.8770,  # RE\n",
    "    -38.5016,  # SA\n",
    "    -47.8828,  # BR\n",
    "    -43.9345,  # BH\n",
    "    -56.0979,  # CI\n",
    "    -43.1729,  # RJ\n",
    "    -46.6333,  # SP\n",
    "    -49.2733,  # CR\n",
    "    -48.5480,  # FL\n",
    "    -51.2177,  # PA\n",
    "]\n",
    "\n",
    "airports_df = pd.DataFrame({\n",
    "    \"id\": np.arange(len(airport_codes), dtype=np.int32),\n",
    "    \"code\": airport_codes,\n",
    "    \"name\": airport_names,\n",
    "    \"lat\": airport_lat,\n",
    "    \"lon\": airport_lon,\n",
    "})\n",
    "\n",
    "airports_csv_path  = BASE_DIR / \"airports.csv\"\n",
    "airports_json_path = BASE_DIR / \"airports.json\"\n",
    "\n",
    "airports_df.to_csv(airports_csv_path, index=False)\n",
    "\n",
    "with open(airports_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\n",
    "        \"airports\": airports_df.to_dict(orient=\"records\")\n",
    "    }, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Salvos:\")\n",
    "print(\" -\", airports_csv_path)\n",
    "print(\" -\", airports_json_path)\n",
    "\n",
    "# Oferecer download local\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1763659602032,
     "user": {
      "displayName": "Lucas Collevatti",
      "userId": "15100666009399473044"
     },
     "user_tz": 180
    },
    "id": "dMh8A98fKgOK",
    "outputId": "8b230a76-bacb-4901-daf5-a7d0bc239211"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz TAB_TV construída. Simétrica?: True\n",
      "Salvo: C:\\Users\\lucas\\Projects\\Softwares\\PSI3472\\airnet_inputs\\tab_tv.csv\n",
      "Salvos:\n",
      " - C:\\Users\\lucas\\Projects\\Softwares\\PSI3472\\airnet_inputs\\routes.csv\n",
      " - C:\\Users\\lucas\\Projects\\Softwares\\PSI3472\\airnet_inputs\\routes.json\n",
      "Total de rotas: 182\n"
     ]
    }
   ],
   "source": [
    "# A3 - TAB_TV (tempos de voo) e rotas\n",
    "\n",
    "codes = airport_codes\n",
    "n = len(codes)\n",
    "\n",
    "# TABELA DO ENUNCIADO (13 valores por linha, sem diagonal)\n",
    "tv_rows = {\n",
    "    \"MA\": [120, 180, 180, 180, 180, 180, 240, 180, 300, 300, 300, 360, 360],\n",
    "    \"BE\": [120, 120, 120, 120, 180, 180, 240, 180, 240, 240, 300, 300, 360],\n",
    "    \"FO\": [180, 120,  60,  60, 120, 180, 180, 240, 240, 240, 300, 300, 360],\n",
    "    \"NA\": [180, 120,  60,  60, 120, 180, 180, 240, 240, 240, 300, 300, 360],\n",
    "    \"RE\": [180, 120,  60,  60, 120, 180, 180, 240, 180, 180, 240, 240, 300],\n",
    "    \"SA\": [180, 180, 120, 120, 120, 120, 120, 180, 120, 120, 180, 180, 240],\n",
    "    \"BR\": [180, 180, 180, 180, 180, 120,  60,  60, 120, 120, 180, 180, 240],\n",
    "    \"BH\": [240, 240, 180, 180, 180, 120,  60, 120,  60,  60, 120, 120, 180],\n",
    "    \"CI\": [180, 180, 240, 240, 240, 180,  60, 120, 180, 180, 180, 180, 240],\n",
    "    \"RJ\": [300, 240, 240, 240, 180, 120, 120,  60, 180,  60, 120, 120, 180],\n",
    "    \"SP\": [300, 240, 240, 240, 180, 120, 120,  60, 180,  60,  60,  60, 120],\n",
    "    \"CR\": [300, 300, 300, 300, 240, 180, 180, 120, 180, 120,  60,  60,  60],\n",
    "    \"FL\": [360, 300, 300, 300, 240, 180, 180, 120, 180, 120,  60,  60,  60],\n",
    "    \"PA\": [360, 360, 360, 360, 300, 240, 240, 180, 240, 180, 120,  60,  60],\n",
    "}\n",
    "\n",
    "# Montar matriz 14x14 com diag=0\n",
    "TAB_TV = np.zeros((n, n), dtype=int)\n",
    "\n",
    "for i, orig in enumerate(codes):\n",
    "    vals = tv_rows[orig]\n",
    "    k = 0\n",
    "    for j, dest in enumerate(codes):\n",
    "        if i == j:\n",
    "            TAB_TV[i, j] = 0\n",
    "        else:\n",
    "            TAB_TV[i, j] = vals[k]\n",
    "            k += 1\n",
    "\n",
    "# Checar (opcional): simetria aproximada\n",
    "print(\"Matriz TAB_TV construída. Simétrica?:\", np.all(TAB_TV == TAB_TV.T))\n",
    "\n",
    "# Salvar TAB_TV em formato de matriz tipo slide do professor\n",
    "tv_df = pd.DataFrame(TAB_TV, index=codes, columns=codes)\n",
    "tv_csv_path = BASE_DIR / \"tab_tv.csv\"\n",
    "tv_df.to_csv(tv_csv_path)\n",
    "print(\"Salvo:\", tv_csv_path)\n",
    "\n",
    "# Construir lista de rotas (orig_id, dest_id, time_min) para JSON/CSV\n",
    "routes = []\n",
    "route_id = 0\n",
    "for i, orig in enumerate(codes):\n",
    "    for j, dest in enumerate(codes):\n",
    "        if i == j:\n",
    "            continue\n",
    "        t = int(TAB_TV[i, j])\n",
    "        if t <= 0:\n",
    "            continue\n",
    "        routes.append({\n",
    "            \"route_id\": route_id,\n",
    "            \"orig_id\": i,\n",
    "            \"dest_id\": j,\n",
    "            \"orig_code\": orig,\n",
    "            \"dest_code\": dest,\n",
    "            \"time_min\": t\n",
    "        })\n",
    "        route_id += 1\n",
    "\n",
    "routes_df = pd.DataFrame(routes)\n",
    "\n",
    "routes_csv_path  = BASE_DIR / \"routes.csv\"\n",
    "routes_json_path = BASE_DIR / \"routes.json\"\n",
    "\n",
    "routes_df.to_csv(routes_csv_path, index=False)\n",
    "with open(routes_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"routes\": routes}, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Salvos:\")\n",
    "print(\" -\", routes_csv_path)\n",
    "print(\" -\", routes_json_path)\n",
    "print(\"Total de rotas:\", len(routes_df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1763659602032,
     "user": {
      "displayName": "Lucas Collevatti",
      "userId": "15100666009399473044"
     },
     "user_tz": 180
    },
    "id": "xsycOJznKh-n",
    "outputId": "dfdec808-58cc-4061-e53f-2c590ffdb8b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo: C:\\Users\\lucas\\Projects\\Softwares\\PSI3472\\airnet_inputs\\tab_od.csv\n",
      "Demanda total (TAB_OD): 94800\n",
      "Salvo: C:\\Users\\lucas\\Projects\\Softwares\\PSI3472\\airnet_inputs\\passengers.json\n",
      "N pares OD com demanda > 0 : 182\n"
     ]
    }
   ],
   "source": [
    "# A4 - TAB_OD (Origem-Destino, #passageiros) e passengers.json\n",
    "\n",
    "od_rows = {\n",
    "    \"MA\": [350, 200, 200, 300, 200, 500, 200, 200, 400, 800, 300, 200, 300],\n",
    "    \"BE\": [400, 400, 300, 200, 300, 500, 200, 100, 400, 900, 300, 200, 200],\n",
    "    \"FO\": [300, 350, 500, 400, 400, 600, 300, 200, 500, 900, 300, 300, 400],\n",
    "    \"NA\": [200, 300, 400, 300, 400, 400, 200, 300, 400, 600, 300, 300, 300],\n",
    "    \"RE\": [300, 400, 600, 400, 600, 500, 300, 300, 800, 800, 400, 400, 400],\n",
    "    \"SA\": [200, 200, 800, 600, 600, 400, 400, 400, 800, 1100, 500, 500, 500],\n",
    "    \"BR\": [500, 500, 900, 500, 700, 900, 700, 800, 1400, 2500, 600, 600, 800],\n",
    "    \"BH\": [200, 300, 400, 200, 500, 200, 500, 200, 600, 900, 300, 200, 200],\n",
    "    \"CI\": [200, 200, 300, 200, 200, 200, 300, 200, 200, 400, 100, 100, 200],\n",
    "    \"RJ\": [600, 700, 900, 600, 1000, 900, 1600, 900, 900, 3400, 900, 800, 900],\n",
    "    \"SP\": [800, 900, 1100, 700, 1400, 1300, 2500, 100, 800, 2800, 1500, 1200, 1100],\n",
    "    \"CR\": [100, 200, 300, 200, 200, 400, 500, 300, 200, 600, 800, 300, 500],\n",
    "    \"FL\": [100, 150, 200, 500, 300, 200, 600, 400, 200, 600, 600, 500, 300],\n",
    "    \"PA\": [100, 250, 200, 400, 300, 400, 500, 300, 200, 700, 800, 300, 300],\n",
    "}\n",
    "\n",
    "TAB_OD = np.zeros((n, n), dtype=int)\n",
    "\n",
    "for i, orig in enumerate(codes):\n",
    "    vals = od_rows[orig]\n",
    "    k = 0\n",
    "    for j, dest in enumerate(codes):\n",
    "        if i == j:\n",
    "            TAB_OD[i, j] = 0\n",
    "        else:\n",
    "            TAB_OD[i, j] = vals[k]\n",
    "            k += 1\n",
    "\n",
    "od_df = pd.DataFrame(TAB_OD, index=codes, columns=codes)\n",
    "od_csv_path = BASE_DIR / \"tab_od.csv\"\n",
    "od_df.to_csv(od_csv_path)\n",
    "print(\"Salvo:\", od_csv_path)\n",
    "\n",
    "total_demand = int(TAB_OD.sum())\n",
    "print(\"Demanda total (TAB_OD):\", total_demand)\n",
    "\n",
    "# passengers.json em formato agregado (um registro por par OD)\n",
    "passengers_agg = []\n",
    "pid = 0\n",
    "for i, orig in enumerate(codes):\n",
    "    for j, dest in enumerate(codes):\n",
    "        if i == j:\n",
    "            continue\n",
    "        d = int(TAB_OD[i, j])\n",
    "        if d <= 0:\n",
    "            continue\n",
    "        passengers_agg.append({\n",
    "            \"id\": pid,\n",
    "            \"orig_id\": i,\n",
    "            \"dest_id\": j,\n",
    "            \"orig_code\": codes[i],\n",
    "            \"dest_code\": codes[j],\n",
    "            \"demand\": d\n",
    "        })\n",
    "        pid += 1\n",
    "\n",
    "passengers_json_path = BASE_DIR / \"passengers.json\"\n",
    "with open(passengers_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"od_pairs\": passengers_agg}, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Salvo:\", passengers_json_path)\n",
    "print(\"N pares OD com demanda >\", 0, \":\", len(passengers_agg))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1763659602032,
     "user": {
      "displayName": "Lucas Collevatti",
      "userId": "15100666009399473044"
     },
     "user_tz": 180
    },
    "id": "39Lj1VtKKkry",
    "outputId": "19ed010d-7857-4e28-ce17-2bfc91c621a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo: C:\\Users\\lucas\\Projects\\Softwares\\PSI3472\\airnet_inputs\\fleet.json\n",
      "Salvo: C:\\Users\\lucas\\Projects\\Softwares\\PSI3472\\airnet_inputs\\meta.json\n",
      "\n",
      "Resumo final dos arquivos na pasta:\n",
      " - airports.csv\n",
      " - airports.json\n",
      " - Brazil_Blank_Map.svg\n",
      " - Brazil_states_blank.png\n",
      " - fleet.json\n",
      " - flights_ga.json\n",
      " - forbidden_routes.json\n",
      " - ga_stats.json\n",
      " - meta.json\n",
      " - passengers.json\n",
      " - passengers_flights.json\n",
      " - relatorio_trafego_aereo.pdf\n",
      " - routes.csv\n",
      " - routes.json\n",
      " - TAB_AP_passageiros_grupos.csv\n",
      " - TAB_AV_voos.csv\n",
      " - tab_od.csv\n",
      " - tab_tv.csv\n"
     ]
    }
   ],
   "source": [
    "# A5 - Gerar fleet.json e meta.json (para o GA/Qt)\n",
    "\n",
    "fleet = {\n",
    "    \"num_aircraft\": int(FLEET_N),\n",
    "    \"seats_per_aircraft\": int(SEATS_PER),\n",
    "    \"aircraft_ids\": [f\"AC_{i:03d}\" for i in range(FLEET_N)],\n",
    "}\n",
    "\n",
    "fleet_path = BASE_DIR / \"fleet.json\"\n",
    "with open(fleet_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(fleet, f, indent=2, ensure_ascii=False)\n",
    "print(\"Salvo:\", fleet_path)\n",
    "\n",
    "meta = {\n",
    "    \"day_start\": DAY_START,\n",
    "    \"day_end\": DAY_END,\n",
    "    \"slot_min\": SLOT_MIN,\n",
    "    \"turnaround_min\": TURNAROUND_MIN,\n",
    "    \"min_conn_min\": MIN_CONN_MIN,\n",
    "    \"fleet_n\": FLEET_N,\n",
    "    \"seats_per_aircraft\": SEATS_PER,\n",
    "    \"airport_order\": codes,\n",
    "    \"total_demand_od\": int(TAB_OD.sum()),\n",
    "}\n",
    "\n",
    "meta_path = BASE_DIR / \"meta.json\"\n",
    "with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, indent=2, ensure_ascii=False)\n",
    "print(\"Salvo:\", meta_path)\n",
    "\n",
    "print(\"\\nResumo final dos arquivos na pasta:\")\n",
    "for p in BASE_DIR.iterdir():\n",
    "    print(\" -\", p.name)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNKaZNa20zto6VQovxm+IQn",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
